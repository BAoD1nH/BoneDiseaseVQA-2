import os
import torch
import pandas as pd
from transformers import AutoTokenizer, AutoFeatureExtractor
from model_arch import BoneDiseaseVQA
from dataset import MedicalVQADataset

# Constants
VISION_MODEL = 'microsoft/swinv2-base-patch4-window8-256'
TEXT_MODEL = 'vimednli/vihealthbert-w_mlm-ViMedNLI'
MODEL_PATH = 'checkpoints/best_model.pt'
QUESTION_CSV = 'dataset/question_bonedata.csv'
IMAGE_ROOT = '/kaggle/input/bonevqa/DemoBoneData'
LABEL_MAP_FILE = 'label_map_idx2label.json'

# Load label mapping
with open(LABEL_MAP_FILE, 'r', encoding='utf-8') as f:
    idx2label = json.load(f)

# Load the model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = BoneDiseaseVQA(
    vision_model_name=VISION_MODEL,
    text_model_name=TEXT_MODEL,
    answer_classes=list(idx2label.values())
).to(device)
model.load_state_dict(torch.load(MODEL_PATH))
model.eval()

# Load tokenizer and feature extractor
tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL)
feature_extractor = AutoFeatureExtractor.from_pretrained(VISION_MODEL)

# Load questions
questions_df = pd.read_csv(QUESTION_CSV)

def infer(image_path, question):
    # Prepare inputs
    pixel_values = feature_extractor(images=image_path, return_tensors="pt").pixel_values.to(device)
    inputs = tokenizer(question, return_tensors="pt", padding=True, truncation=True).to(device)

    # Perform inference
    with torch.no_grad():
        logits = model(pixel_values, inputs['input_ids'], inputs['attention_mask'])
        preds = torch.argmax(logits, dim=1)
    
    return idx2label[str(preds.item())]

# Example usage
if __name__ == "__main__":
    for index, row in questions_df.iterrows():
        image_path = os.path.join(IMAGE_ROOT, row['image_filename'])  # Assuming the CSV has a column for image filenames
        question = row['question']  # Assuming the CSV has a column for questions
        prediction = infer(image_path, question)
        print(f"Question: {question} | Prediction: {prediction}")